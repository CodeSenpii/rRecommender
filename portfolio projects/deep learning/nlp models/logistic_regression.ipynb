{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBz6CYlud_12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d91b71c9-cd16-4ae9-fa5f-1a4581aba1eb"
      },
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n",
        "\n",
        "def build_freqs(tweets, ys):\n",
        "    \"\"\"Build frequencies.\n",
        "    Input:\n",
        "        tweets: a list of tweets\n",
        "        ys: an m x 1 array with the sentiment label of each tweet\n",
        "            (either 0 or 1)\n",
        "    Output:\n",
        "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
        "        frequency\n",
        "    \"\"\"\n",
        "    # Convert np array to list since zip needs an iterable.\n",
        "    # The squeeze is necessary or the list ends up with one element.\n",
        "    # Also note that this is just a NOP if ys is already a list.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Start with an empty dictionary and populate it by looping over all tweets\n",
        "    # and over all processed words in each tweet.\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-q7WzzYdtZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk                         # NLP toolbox\n",
        "from os import getcwd\n",
        "import pandas as pd                 # Library for Dataframes \n",
        "from nltk.corpus import twitter_samples \n",
        "import matplotlib.pyplot as plt     # Library for visualization\n",
        "import numpy as np                  # Library for math functions\n",
        "\n",
        "from utils import process_tweet, build_freqs # Our functions for NLP"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIMVYmvgeTuf",
        "colab_type": "text"
      },
      "source": [
        "#Load the NLTK sample dataset\n",
        "To complete this lab, you need the sample dataset of the previous lab. Here, we assume the files are already available, and we only need to load into Python lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOAP0zZ8dvsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98a9f8b3-e02c-489a-b3eb-57fe3748614b"
      },
      "source": [
        "nltk.download(\"twitter_samples\")\n",
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "tweets = all_positive_tweets + all_negative_tweets ## Concatenate the lists. \n",
        "labels = np.append(np.ones((len(all_positive_tweets),1)), np.zeros((len(all_negative_tweets),1)), axis = 0)\n",
        "\n",
        "# split the data into two pieces, one for training and one for testing (validation set) \n",
        "train_pos  = all_positive_tweets[:4000]\n",
        "train_neg  = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg \n",
        "\n",
        "print(\"Number of tweets: \", len(train_x))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "Number of tweets:  8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va5sOpz1e0CQ",
        "colab_type": "text"
      },
      "source": [
        "#Load the extracted features\n",
        "Part of this week's assignment is the creation of the numerical features needed for the Logistic regression model. In order not to interfere with it, we have previously calculated and stored these features in a CSV file for the entire training set.\n",
        "\n",
        "So, please load these features created for the tweets sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMMOH8BFecB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d9106c97-9ff0-49e0-980f-16322b1ad21e"
      },
      "source": [
        "data = pd.read_csv('logistic_features.csv'); # Load a 3 columns csv file using pandas function\n",
        "data.head(10) # Print the first 10 data entries"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bias</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3020.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3573.0</td>\n",
              "      <td>444.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3005.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2862.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3119.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2955.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3934.0</td>\n",
              "      <td>538.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3162.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>628.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  bias positive negative sentiment\n",
              "0  1.0   3020.0     61.0       1.0\n",
              "1  1.0   3573.0    444.0       1.0\n",
              "2  1.0   3005.0    115.0       1.0\n",
              "3  1.0   2862.0      4.0       1.0\n",
              "4  1.0   3119.0    225.0       1.0\n",
              "5  1.0   2955.0    119.0       1.0\n",
              "6  1.0   3934.0    538.0       1.0\n",
              "7  1.0   3162.0    276.0       1.0\n",
              "8  1.0    628.0    189.0       1.0\n",
              "9  1.0    264.0    112.0       1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LixdzKGofNhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "63317583-93c6-4703-d76c-b8aec62b95f2"
      },
      "source": [
        "# Each feature is labeled as bias, positive and negative\n",
        "X = data[['bias', 'positive', 'negative']].values # Get only the numerical values of the dataframe\n",
        "Y = data['sentiment'].values; # Put in Y the corresponding labels or sentiments\n",
        "\n",
        "print(X.shape) # Print the shape of the X part\n",
        "print(X) # Print some rows of X"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16001, 3)\n",
            "[['1.0' '3020.0' '61.0']\n",
            " ['1.0' '3573.0' '444.0']\n",
            " ['1.0' '3005.0' '115.0']\n",
            " ...\n",
            " ['1.0' '144.0' '783.0']\n",
            " ['1.0' '205.0' '3890.0']\n",
            " ['1.0' '189.0' '3974.0']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7537EJ3PfQEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = [7e-08, 0.0005239, -0.00055517]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P75rvhMgCA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a1c6466-9f5c-421f-9ae1-32ef90fd4cf7"
      },
      "source": [
        "Y[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1.0', '1.0', '1.0', '1.0', '1.0'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4GHi7THfgFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the samples using columns 1 and 2 of the matrix\n",
        "fig, ax = plt.subplots(figsize = (8, 8))\n",
        "\n",
        "colors = ['red', 'green']\n",
        "\n",
        "# Color based on the sentiment Y\n",
        "ax.scatter(X[:,1], X[:,2], c=[colors[int(float(int(k)))] for k in Y], s = 0.1)  # Plot a dot for each pair of words\n",
        "plt.xlabel(\"Positive\")\n",
        "plt.ylabel(\"Negative\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwHAb_yrfizo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the samples using columns 1 and 2 of the matrix\n",
        "fig, ax = plt.subplots(figsize = (8, 8))\n",
        "\n",
        "colors = ['red', 'green']\n",
        "\n",
        "# Color base on the sentiment Y\n",
        "ax.scatter(X[:,1], X[:,2], c=[colors[int(k)] for k in Y], s = 0.1)  # Plot a dot for each pair of words\n",
        "plt.xlabel(\"Positive\")\n",
        "plt.ylabel(\"Negative\")\n",
        "\n",
        "# Now lets represent the logistic regression model in this chart. \n",
        "maxpos = np.max(X[:,1])\n",
        "\n",
        "offset = 5000 # The pos value for the direction vectors origin\n",
        "\n",
        "# Plot a gray line that divides the 2 areas.\n",
        "ax.plot([0,  maxpos], [neg(theta, 0),   neg(theta, maxpos)], color = 'gray') \n",
        "\n",
        "# Plot a green line pointing to the positive direction\n",
        "ax.arrow(offset, neg(theta, offset), offset, direction(theta, offset), head_width=500, head_length=500, fc='g', ec='g')\n",
        "# Plot a red line pointing to the negative direction\n",
        "ax.arrow(offset, neg(theta, offset), -offset, -direction(theta, offset), head_width=500, head_length=500, fc='r', ec='r')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ4ViQ1igblv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}